{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a300fa97-41b6-449e-ac22-b90d13aa392c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.11/site-packages (4.57.0)\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.11/site-packages (1.10.1)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.11/site-packages (10.3.0)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.11/site-packages (2.5.1)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.11/site-packages (0.20.1)\n",
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.49.0-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.35.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (2025.9.18)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2024.3.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from accelerate) (7.1.0)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch) (3.4)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2025.10.5)\n",
      "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading bitsandbytes-0.49.0-py3-none-manylinux_2_24_x86_64.whl (59.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sympy, bitsandbytes\n",
      "\u001b[2K  Attempting uninstall: sympy\n",
      "\u001b[2K    Found existing installation: sympy 1.14.0\n",
      "\u001b[2K    Uninstalling sympy-1.14.0:\n",
      "\u001b[2K      Successfully uninstalled sympy-1.14.0━━━━━\u001b[0m \u001b[32m0/2\u001b[0m [sympy]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [bitsandbytes][0m [bitsandbytes]\n",
      "\u001b[1A\u001b[2KSuccessfully installed bitsandbytes-0.49.0 sympy-1.13.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers accelerate pillow torch torchvision bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98d54fc9-b6f3-48e2-9dc4-e0bec61c3a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 19:14:17.253429: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/tmp/ipykernel_1685/1014933687.py:30: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  resnet.load_state_dict(torch.load(\"outputs/resnet_best.pt\", map_location=device))\n",
      "The image processor of type `Qwen2VLImageProcessor` is now loaded as a fast processor by default, even if the model checkpoint was saved with a slow processor. This is a breaking change and may produce slightly different outputs. To continue using the slow processor, instantiate this class with `use_fast=False`. Note that this behavior will be extended to all models in a future release.\n",
      "/opt/conda/lib/python3.11/site-packages/transformers/models/auto/modeling_auto.py:2284: FutureWarning: The class `AutoModelForVision2Seq` is deprecated and will be removed in v5.0. Please use `AutoModelForImageTextToText` instead.\n",
      "  warnings.warn(\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98287f6c31e546dbbe8b9a3326c114cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet-Klasse: Excel\n",
      "[QWEN] Baue messages...\n",
      "[QWEN] Wende chat template an...\n",
      "[QWEN] Erzeuge Inputs...\n",
      "[QWEN] input_ids shape: (1, 1506)\n",
      "[QWEN] attention_mask shape: (1, 1506)\n",
      "[QWEN] pixel_values shape: (5336, 1176)\n",
      "[QWEN] image_grid_thw shape: (1, 3)\n",
      "[QWEN] Starte generate()...\n",
      "[QWEN] generate() fertig.\n",
      "[QWEN] Decoding fertig.\n",
      "\n",
      "JSON-Ausgabe:\n",
      "system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "\n",
      "Extrahiere die tabellarischen Daten aus dem Excel-Screenshot.\n",
      "Ignoriere UI-Elemente wie Menüleisten, Filterbereiche, Metadaten oder Seitentitel.\n",
      "Konzentriere dich ausschließlich auf die sichtbare Tabelle.\n",
      "\n",
      "Gib NUR gültiges JSON zurück.\n",
      "KEIN Markdown.\n",
      "KEINE ```json Blöcke.\n",
      "KEINE Erklärungen.\n",
      "KEINE Kommentare.\n",
      "KEINE zusätzlichen Texte.\n",
      "\n",
      "Format:\n",
      "\n",
      "{\n",
      "  \"columns\": [\"Spalte1\", \"Spalte2\", ...],\n",
      "  \"rows\": [\n",
      "    [\"Wert1\", \"Wert2\", ...],\n",
      "    [\"Wert1\", \"Wert2\", ...]\n",
      "  ]\n",
      "}\n",
      "\n",
      "assistant\n",
      "{\n",
      "  \"columns\": [\"Product\", \"Deviation %\", \"Revenue $\", \"Revenue 1. Quartal 2018 EUR\", \"Revenue 1. Quartal 2019 EUR\", \"Revenue 2018 EUR\", \"Sales Quantity PC\"],\n",
      "  \"rows\": [\n",
      "    [\"Overall Result\", \"6,5\", \"954.574.883,68\", \"8.061.910,76\", \"8.589.880,69\", \"70.340.548,43\", \"297.152\"],\n",
      "    [\"City Bike Mas\", \"-84,4\", \"4.051.591,98\", \"78.505,92\", \"12.281,23\", \"294.297,20\", \"2.188\"],\n",
      "    [\"Deluxe Road Bike (Shimano)\", \"10,8\", \"70.523.753,67\", \"537.546,90\", \"594.531,80\", \"4.880.555,13\", \"33.878\"],\n",
      "    [\"Deluxe Road Bike (SRAM)\", \"13,0\", \"23.095.145,11\", \"230.284,80\", \"274.048,84\", \"1.808.095,50\", \"11.428\"],\n",
      "    [\"Deluxe Touring Bike (silver)\", \"-6,1\", \"113.324.854,29\", \"1.050.016,68\", \"986.012,14\", \"9.668.041,40\", \"30.634\"],\n",
      "    [\"Fixed Gear Bike Plus\", \"-54,0\", \"1.604.023,40\", \"18.318,02\", \"8.421,42\", \"125.609,28\", \"1.086\"],\n",
      "    [\"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, AutoModelForVision2Seq\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "num_classes = 13\n",
    "class_names = [\n",
    "    \"ABAP Dictionary\",\n",
    "    \"BW4Cockpit (Stammdaten)\",\n",
    "    \"Bewegungsdaten\",\n",
    "    \"Composite Provider\",\n",
    "    \"DTP\",\n",
    "    \"Data Flow Object\",\n",
    "    \"Data Mart\",\n",
    "    \"Data Source\",\n",
    "    \"Data Store Object\",\n",
    "    \"Datenvorschau\",\n",
    "    \"Excel\",\n",
    "    \"Query\",\n",
    "    \"Transformationen\"\n",
    "]\n",
    "\n",
    "resnet = models.resnet18(weights=None)\n",
    "resnet.fc = torch.nn.Linear(resnet.fc.in_features, num_classes)\n",
    "resnet.load_state_dict(torch.load(\"outputs/resnet_best.pt\", map_location=device))\n",
    "resnet = resnet.to(device)\n",
    "resnet.eval()\n",
    "\n",
    "\n",
    "model_id = \"Qwen/Qwen2.5-VL-7B-Instruct\"\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id, token=\"none\")\n",
    "\n",
    "qwen = AutoModelForVision2Seq.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.float16 if device == \"cuda\" else torch.float32,\n",
    "    device_map=\"auto\",\n",
    "    token=\"none\"\n",
    ")\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def classify_image(image_path):\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    tensor = transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = resnet(tensor)\n",
    "        _, pred = torch.max(outputs, 1)\n",
    "\n",
    "    return class_names[pred.item()], img\n",
    "\n",
    "\n",
    "PROMPTS = {\n",
    "    \"Excel\": \"\"\"\n",
    "Extrahiere die tabellarischen Daten aus dem Excel-Screenshot.\n",
    "Ignoriere UI-Elemente wie Menüleisten, Filterbereiche, Metadaten oder Seitentitel.\n",
    "Konzentriere dich ausschließlich auf die sichtbare Tabelle.\n",
    "\n",
    "Gib NUR gültiges JSON zurück.\n",
    "KEIN Markdown.\n",
    "KEINE ```json Blöcke.\n",
    "KEINE Erklärungen.\n",
    "KEINE Kommentare.\n",
    "KEINE zusätzlichen Texte.\n",
    "\n",
    "Format:\n",
    "\n",
    "{\n",
    "  \"columns\": [\"Spalte1\", \"Spalte2\", ...],\n",
    "  \"rows\": [\n",
    "    [\"Wert1\", \"Wert2\", ...],\n",
    "    [\"Wert1\", \"Wert2\", ...]\n",
    "  ]\n",
    "}\n",
    "\"\"\",\n",
    "\n",
    "    \"DTP\": \"\"\"\n",
    "Analysiere den Screenshot eines Data Transfer Process (DTP) in SAP BW/4HANA.\n",
    "\n",
    "Extrahiere ausschließlich die für einen DTP relevanten Informationen:\n",
    "\n",
    "- DTP-Name bzw. technische ID\n",
    "- Ausführungsmodus (z. B. Serial SAP HANA Execution, Dialog, Hintergrund)\n",
    "- Quelle des DTP (z. B. DataSource, RSDS, Datei)\n",
    "- Zielobjekt (z. B. ADSO, InfoCube)\n",
    "- Sichtbare Prozessschritte (z. B. Fill data transfer intermediate storage, Prepare for Extraction, Data Package Loop)\n",
    "- Hinweise auf die Extraktionsart (z. B. Datei-Extraktion)\n",
    "- Sichtbare Systemmeldungen oder Pop-ups (z. B. SAP GUI Security File Access)\n",
    "\n",
    "Gib NUR gültiges JSON zurück.\n",
    "KEIN Markdown.\n",
    "KEINE ```json Blöcke.\n",
    "KEINE Erklärungen.\n",
    "KEINE Kommentare.\n",
    "KEINE zusätzlichen Texte.\n",
    "\n",
    "Format:\n",
    "\n",
    "{\n",
    "  \"dtp_name\": \"\",\n",
    "  \"execution_mode\": \"\",\n",
    "  \"source\": \"\",\n",
    "  \"target\": \"\",\n",
    "  \"process_steps\": [],\n",
    "  \"extraction_type\": \"\",\n",
    "  \"system_messages\": []\n",
    "}\n",
    "\"\"\",\n",
    "\n",
    "        \"Transformationen\": \"\"\"\n",
    "Analysiere den Screenshot einer Transformation in SAP BW/4HANA.\n",
    "\n",
    "Extrahiere ausschließlich die variablen, inhaltlichen Informationen der Transformation:\n",
    "\n",
    "- Name bzw. technische ID der Quelle\n",
    "- Name bzw. technische ID des Ziels\n",
    "- Alle Quellfelder (Name + Datentyp)\n",
    "- Alle Zielfelder (Name + Datentyp)\n",
    "- Alle sichtbaren Feldzuordnungen (source_field → target_field)\n",
    "- Nur echte Mappings, keine Linieninterpretation\n",
    "- Behandle auch farbige, dünne oder schwach sichtbare Linien als gültige Mappings, wenn sie eine Verbindung zwischen zwei Feldern darstellen.\n",
    "- Keine automatisch generierten Felder erfinden\n",
    "\n",
    "Gib NUR gültiges JSON zurück.\n",
    "KEIN Markdown.\n",
    "KEINE ```json Blöcke.\n",
    "KEINE Erklärungen.\n",
    "KEINE Kommentare.\n",
    "KEINE zusätzlichen Texte.\n",
    "\n",
    "Format:\n",
    "\n",
    "{\n",
    "  \"source\": {\n",
    "    \"name\": \"\",\n",
    "    \"fields\": [\n",
    "      {\"name\": \"\", \"type\": \"\"}\n",
    "    ]\n",
    "  },\n",
    "  \"target\": {\n",
    "    \"name\": \"\",\n",
    "    \"fields\": [\n",
    "      {\"name\": \"\", \"type\": \"\"}\n",
    "    ]\n",
    "  },\n",
    "  \"mappings\": [\n",
    "    {\"source_field\": \"\", \"target_field\": \"\"}\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "}\n",
    "\n",
    "\n",
    "def qwen_extract(image, prompt):\n",
    "    print(\"[QWEN] Baue messages...\")\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"image\"},\n",
    "                {\"type\": \"text\", \"text\": prompt}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    print(\"[QWEN] Wende chat template an...\")\n",
    "    text_prompt = processor.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "    print(\"[QWEN] Erzeuge Inputs...\")\n",
    "    inputs = processor(\n",
    "        text=text_prompt,\n",
    "        images=image,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(device)\n",
    "\n",
    "    for k, v in inputs.items():\n",
    "        print(f\"[QWEN] {k} shape:\", tuple(v.shape))\n",
    "\n",
    "    print(\"[QWEN] Starte generate()...\")\n",
    "    output = qwen.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=512,   # jetzt aktiv\n",
    "        do_sample=False,\n",
    "        temperature=0.0,\n",
    "        eos_token_id=None      # jetzt aktiv\n",
    "    )\n",
    "    print(\"[QWEN] generate() fertig.\")\n",
    "\n",
    "    decoded = processor.batch_decode(output, skip_special_tokens=True)[0]\n",
    "    print(\"[QWEN] Decoding fertig.\")\n",
    "    return decoded\n",
    "\n",
    "\n",
    "def process_image(image_path):\n",
    "    pred_class, img = classify_image(image_path)\n",
    "    print(f\"ResNet-Klasse: {pred_class}\")\n",
    "\n",
    "    prompt = PROMPTS[pred_class]\n",
    "    json_output = qwen_extract(img, prompt)\n",
    "\n",
    "    print(\"\\nJSON-Ausgabe:\")\n",
    "    print(json_output)\n",
    "    return json_output\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_image(\"/workspace/Projekt/Testdaten/Data/Ungelabelt/03b359fa5d3d48148433b6d78a2e3cfa.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783b6a8c-38c7-406b-8516-ad2c37a93613",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf1b1ce-ceb8-4628-816a-738f9091c6df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c9d531-3c60-4f40-9b1b-78759d84c9d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
